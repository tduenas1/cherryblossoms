---
title: "Lab 4"
output: rmdformats::material
---

# 3DS : Cherry Blossom

## Lyuda Bekwinknoll, Meghana Cyanam, Theresa Marie Duenas, Kevin Kiser

**Complete the following lab as a group. This document should exist in your GitHub repo while you're working on it. Your code should be heavily commented so someone reading your code can follow along easily. See the first code snippet below for an example of commented code.**

**Here's the catch: For any given problem, the person writing the code should not be the person commenting that code, and every person must both code AND comment at least one problem in this lab (you decide how to split the work). This will involve lots of pushing and pulling through Git, and you may have to resolve conflicts if you're not careful! Refer to last Thursday's class notes for details on conflict resolution.**

**ALSO, all plots generated should have labeled axes, titles, and legends when appropriate. Don't forget units of measurement! Make sure these plots could be interpreted by your client.**

These problems were adapted from **Cleaning Data for Effective Data Science** by David Mertz

```{r, message = F}
# load packages
library(dplyr)
library(stringdist)
library(ggplot2)
library(gridExtra)
library(Hmisc)

```

# Dealing With Outliers

**The Michelson--Morley experiment was an attempt in the late 19th century to detect the existence of the luminiferous aether, a widely assumed medium that would carry light waves. This was the most famous "failed experiment" in the history of physics in that it did not detect what it was looking for---something we now know not to exist at all.**

**The general idea was to measure the speed of light under different orientations of the equipment relative to the direction of movement of the Earth, since relative movement of the ether medium would add or subtract from the speed of the wave. Yes, it does not work that way under the theory of relativity, but it was a reasonable guess 150 years ago.**

**Apart from the physics questions, the dataset derived by the Michelson--Morley experiment is widely available, including the sample given in `morley.dat`. The specific numbers in this data are measurements of the speed of light in km/s with a zero point of 299,000. So, for example, the mean measurement in experiment 1 was 299,909 km/s (you can check this when you load the data).**

```{r}

morley <- read.table("morley.dat", header = TRUE)

summary(morley)
```

Looking at the overall statistics, it seems like the data I was given differs from the data described up above, but I will do what the questions ask with the data I was given.

**1. Using R to identify the outliers first within each setup (defined by the `Expt` number) and then within the data collection as a whole. The hope in the original experiment was that each setup would show a significant difference in central tendency. We did not cover confidence levels and null hypotheses, so simply create visualization(s) that aids you in gaining insight into how much apparent difference exists between the several setups.**

```{r}

summary_stats <- morley %>%
  group_by(Expt) %>%
  summarise(
    Mean = mean(Speed),    
    Min = min(Speed),
    Q1 = quantile(Speed, 0.25),
    Median = median(Speed),
    Q3 = quantile(Speed, 0.75),
    Max = max(Speed)
  )


overall_stats <- morley %>%
  summarise(
    Mean = mean(Speed),
    Min = min(Speed),
    Q1 = quantile(Speed, 0.25),
    Median = median(Speed),
    Q3 = quantile(Speed, 0.75),
    Max = max(Speed)
  )


summary_stats <- bind_rows(summary_stats, overall_stats)
```

```{r}

subset_summary_stats <- summary_stats[1:5, ]

p1 <- ggplot(morley, aes(x = factor(Expt), y = Speed)) +
  geom_boxplot() +
  geom_text(data = subset_summary_stats, 
            aes(x = Expt, y = 1050, label = sprintf("Max: %.1f", Max)), vjust = 0, hjust = 0.5) +
  geom_text(data = subset_summary_stats, 
            aes(x = Expt, y = 1020, label = sprintf("Q3: %.1f", Q3)), vjust = 0, hjust = 0.5) +
  geom_text(data = subset_summary_stats,
            aes(x = Expt, y = 920, label = sprintf("Median: %.1f", Median)), vjust = 0, hjust = 0.5) +
  geom_text(data = subset_summary_stats,
            aes(x = Expt, y = 890, label = sprintf("Mean: %.1f", Mean)), vjust = 0, hjust = 0.5) +
  geom_text(data = subset_summary_stats,
            aes(x = Expt, y = 655, label = sprintf("Q1: %.1f", Q1)), vjust = 0, hjust = 0.5) +
  geom_text(data = subset_summary_stats,
            aes(x = Expt, y = 620, label = sprintf("Min: %.1f", Min)), vjust = 0, hjust = 0.5) +
  labs(title = "Boxplot of Speed by Experiment",
       x = "Experiment Number",
       y = "Speed (km/s)")


subset1_summary_stats <- summary_stats[6, ]


p2 <- ggplot(morley, aes(x = 1, y = Speed)) +
  geom_boxplot() +
  geom_text(data = subset1_summary_stats,
            aes(x = 1, y = 1050, label = sprintf("Max: %.1f", Max)), vjust = 0, hjust = 1.1) +
  geom_text(data = subset1_summary_stats, 
            aes(x = 1, y = 1000, label = sprintf("Q3: %.1f", Q3)), vjust = 0, hjust = 1.1) +
  geom_text(data = subset1_summary_stats,
            aes(x = 1, y = 920, label = sprintf("Median: %.1f", Median)), vjust = 0, hjust = 1.1) +
  geom_text(data = subset1_summary_stats,
            aes(x = 1, y = 890, label = sprintf("Mean: %.1f", Mean)), vjust = 0, hjust = 1.1) +
  geom_text(data = subset1_summary_stats,
            aes(x = 1, y = 660, label = sprintf("Q1: %.1f", Q1)), vjust = 0, hjust = 1.1) +
  geom_text(data = subset1_summary_stats, 
            aes(x = 1, y = 620, label = sprintf("Min: %.1f", Min)), vjust = 0, hjust = 1.1) +
  labs(title = "Boxplot of Speed by Experiment",
       x = "Overall",
       y = "Speed (km/s)")


grid.arrange(p1, p2, nrow = 2)

```

Looking at the box-plots of each experiment and of the data overall we can locate a few outliers visually. For the box-plots by experiment, the first experiment looks like it has one outlier at 650 and the third experiment looks like it has 4 outliers. Looking at the central tendency per experiment, we don't see much variation between experiments 2-5, but experiment 1 seems to have a higher central tendency compared to the others. Each experiment deviates from each other in its summary statistics, having different means, medians, max, min, Q3, and Q1 values. Experiment 3 seems to have the least variance looking at the space between Q3 and Q1 while Experiment 1 has the most. We can remove the outliers and see how this is impacted in the below question. Each of the Experiments contain similar values in their boxes so we can't say that they show a significant difference in central tendency.

When we look at the data overall, we can see that there are 3 potential outliers in the data.

```{r}


outliers_by_expt <- lapply(levels(factor(morley$Expt)), function(level) {
  subset_data <- morley$Speed[morley$Expt == level]
  out <- boxplot.stats(subset_data)$out
  out_ind <- which(subset_data %in% c(out))
  if (length(out_ind) > 0) {
    return(data.frame(Expt = level, Run = out_ind, Speed = subset_data[out_ind]))
  } else {
    return(NULL)
  }
})


outliers_df <- do.call(rbind, Filter(function(x) !is.null(x), outliers_by_expt))

outliers_df
```

When we extract the outliers from each experiment, we can see that there are 6 outliers. There is one outlier from the first Experiment and 5 from the third Experiment.

```{r}

outliers_full <- boxplot.stats(morley$Speed)$out
outliers_full_indices <- which(morley$Speed %in% outliers_full)


outliers_full_df <- data.frame(
  Expt = morley$Expt[outliers_full_indices],
  Run = outliers_full_indices,
  Speed = morley$Speed[outliers_full_indices]
)


print(outliers_full_df)
```

When we extract the outliers from the full data, we get 3. This time two of them are from the first Experiment and one of them is from the third.

**2. If you discard the outliers within each setup, are the differences between setups increased or decreased? Answer with either a visualization or by looking at statistics on the reduced groups.**

```{r}

outliers_df$Expt <- as.numeric(outliers_df$Expt)


morley_cleaned <- morley %>%
  anti_join(outliers_df, by = c("Expt", "Run"))



summary_stats_cl <- morley_cleaned %>%
  group_by(Expt) %>%
  summarise(
    Mean = mean(Speed),    
    Min = min(Speed),
    Q1 = quantile(Speed, 0.25),
    Median = median(Speed),
    Q3 = quantile(Speed, 0.75),
    Max = max(Speed)
  )


overall_stats_cl <- morley_cleaned %>%
  summarise(
    Mean = mean(Speed),
    Min = min(Speed),
    Q1 = quantile(Speed, 0.25),
    Median = median(Speed),
    Q3 = quantile(Speed, 0.75),
    Max = max(Speed)
  )


summary_stats2 <- bind_rows(summary_stats_cl, overall_stats_cl)
```

```{r}

subset_summary_stats2 <- summary_stats2[1:5, ]

p3 <- ggplot(morley_cleaned, aes(x = factor(Expt), y = Speed)) +
  geom_boxplot() +
  geom_text(data = subset_summary_stats2, 
            aes(x = Expt, y = 1050, label = sprintf("Max: %.1f", Max)), vjust = 0, hjust = 0.5) +
  geom_text(data = subset_summary_stats2, 
            aes(x = Expt, y = 1020, label = sprintf("Q3: %.1f", Q3)), vjust = 0, hjust = 0.5) +
  geom_text(data = subset_summary_stats2, 
            aes(x = Expt, y = 915, label = sprintf("Median: %.1f", Median)), vjust = 0, hjust = 0.5) +
  geom_text(data = subset_summary_stats2, 
            aes(x = Expt, y = 890, label = sprintf("Mean: %.1f", Mean)), vjust = 0, hjust = 0.5) +
  geom_text(data = subset_summary_stats2, 
            aes(x = Expt, y = 735, label = sprintf("Q1: %.1f", Q1)), vjust = 0, hjust = 0.5) +
  geom_text(data = subset_summary_stats2, 
            aes(x = Expt, y = 710, label = sprintf("Min: %.1f", Min)), vjust = 0, hjust = 0.5) +
  labs(title = "Boxplot of Speed by Experiment",
       x = "Experiment Number",
       y = "Speed (km/s)")



subset1_summary_stats2 <- summary_stats2[6, ]

p4 <- ggplot(morley_cleaned, aes(x = 1, y = Speed)) +
  geom_boxplot() +
  geom_text(data = subset1_summary_stats2, 
            aes(x = 1, y = 1050, label = sprintf("Max: %.1f", Max)), vjust = 0, hjust = 1.1) +
  geom_text(data = subset1_summary_stats2, 
            aes(x = 1, y = 1010, label = sprintf("Q3: %.1f", Q3)), vjust = 0, hjust = 1.1) +
  geom_text(data = subset1_summary_stats2, 
            aes(x = 1, y = 915, label = sprintf("Median: %.1f", Median)), vjust = 0, hjust = 1.1) +
  geom_text(data = subset1_summary_stats2, 
            aes(x = 1, y = 890, label = sprintf("Mean: %.1f", Mean)), vjust = 0, hjust = 1.1) +
  geom_text(data = subset1_summary_stats2, 
            aes(x = 1, y = 750, label = sprintf("Q1: %.1f", Q1)), vjust = 0, hjust = 1.1) +
  geom_text(data = subset1_summary_stats2, 
            aes(x = 1, y = 710, label = sprintf("Min: %.1f", Min)), vjust = 0, hjust = 1.1) +
  labs(title = "Boxplot of Speed by Experiment",
       x = "Overall",
       y = "Speed (km/s)")



grid.arrange(p1, p3, nrow = 2)
```

After extracting the outliers, we can see a slight increase in the differences between some of the experiments. Experiments 2-5 still resemble each other a lot because they contain many of the same values, but Experiment 1 deviates a little more from the rest. Outliers were removed from Experiments 1 and 3 since they are the only experiments that had outliers individually. We can see that the mean/median/min values of Experiment 1 increased, and the quantile area shrunk. For Experiment 3, the only thing that changed was the mean and median values grew and the max and min values shrunk in distance. The differences for Experiments 2-5 look roughly the same after removing outliers. For Experiment 1, the common value area that it shared with the other Experiments shrunk, although the other Experiments still contain 30% of similar values with Experiment 1.

```{r}
grid.arrange(p2, p4, nrow = 2)
```

Looking at the overall stats the values didn't change significantly at all. The min value increased since the outliers were removed, but looking at the max value we can still see a value that shows up as an outlier in the overall data that isn't an outlier when we look at the individual experiments.

```{r}
outliers_by_expt2 <- lapply(levels(factor(morley_cleaned$Expt)), function(level) {
  subset_data <- morley_cleaned$Speed[morley_cleaned$Expt == level]
  out <- boxplot.stats(subset_data)$out
  out_ind <- which(subset_data %in% c(out))
  if (length(out_ind) > 0) {
    return(data.frame(Expt = level, Run = out_ind, Speed = subset_data[out_ind]))
  } else {
    return(NULL)
  }
})

outliers_df2 <- do.call(rbind, Filter(function(x) !is.null(x), outliers_by_expt2))

outliers_df2
```

This code above checked for outliers in the individual experiments after removing the initial outliers, it came out null.

```{r}
outliers_full2 <- boxplot.stats(morley_cleaned$Speed)$out
outliers_full_indices2 <- which(morley_cleaned$Speed %in% outliers_full2)

outliers_full_df2 <- data.frame(
  Expt = morley_cleaned$Expt[outliers_full_indices2],
  Run = outliers_full_indices2,
  Speed = morley_cleaned$Speed[outliers_full_indices2]
)

print(outliers_full_df2)
```

This code checked for outliers in the overall data after the removal of the initial outliers, and we got 1 outlier from the 1 Experiment that isn't an outlier when we look at individual experiments.

Concluding thoughts: There were 6 identified outliers in the individual experiments. After the removal of them, we saw a slight increase of differences in Experiment 1 compared to Experiments 2-4, while Experiments 2-4 still looked roughly the same to each other. The differences between the central tendency of all of the Experiments were not big enough to show a significant difference between each other. The overall box-plots looked roughly the same after the removal of the outliers from the individual experiments (although had different min values and the other values also differed slightly but not significantly different). In the end the overall box-plot after the removal of the initial outliers still had one outlier, but that outlier was not an outlier when looking at the individual experiments.

# Mispelled Names

**Our data set `humans-names.csv` contains 25,000 height and weight measurements. Each row has a person's first name pulled from the US Social Security Agency list of common first names over the last century.**

**Unfortunately, our hypothetical data collectors for this dataset are simply terrible typists, and they make typos when entering names with alarming frequency. There are some number of intended names in this dataset, but quite a few simple miscodings of those names as well. Your goal is to clean up these mispelled names.**

```{r}
humans <- readr::read_csv("humans-names.csv", show_col_types = FALSE)
```

1)  **Identify every genuine name and correct all the misspelled ones to the correct canonical spelling. Use all the data wrangling tools you'd like (e.g. `dplyr` functions), but make sure you're checking each reassignment to make sure the names get classified correctly. You'll fully automate this process later. It is probably reasonable to assume that rare spellings are typos, at least if they are also relatively similar to common spellings.\
    Hint: There are a number of ways to measure the similarity of strings and that provide a clue as to likely typos. One general class of approach is in terms of edit distance between strings, which describes how many editing operations need to be done to transform one string into another. The R package `stringdist` provides Damerau--Levenshtein, Hamming, Levenshtein, and optimal string alignment as measures of edit distance. Keep in mind that sometimes multiple legitimate names are actually close to each other in terms of similarity measures (Dan VS Don, Jacob VS Jakob, etc). If you want to use `stringdist` for this problem, start by looking at the functions `stringdist()` and `stringdistmatrix()`.**

```{r}
# unique names
unique_names <- humans$Name %>% unique(.)

# number of unique names
num_names <- humans$Name %>% table(.)
```

```{r}
names_to_replace <- list(
  c("ames", "Jamse", "Jamees", "Jmes", "Jaems", "Jame", "eJeames", "eJames", 
    "Jaemes", "Jeames", "Jmaes", "sameJ"),
  
  c("aBrbara", "Babara", "Barabra", "Barara", "Babrara", "Baerbara", "Barbaar", 
    "Barbaera", "arbara", "eBarbara", "Barebara", "Barbraa", "Brabara",
    "Barbar", "Barbarea"),
  
  c("aDvid", "aevid", "avid", "Daevid", "Daevid", "Daivd", "Davd", "Davdi", 
    "Daveid", "Davi", "daviD", "Davied", "Deavid", "Dvaid", "Dvid", "eDavid"),
  
  c("Eilzabeth", "Eliezabeth", "Elizabeeth", "Elizabeh", "Elizabeht", 
    "Elizabet", "Elizabeteh", "Elizabteh","Elizaebeth", "Elizeabeth", 
    "lEizabeth"),
  
  c("Jeessica", "Jesica", "Jesscia", "Jesseica", "Jessia", "Jessiac", 
    "Jessicea", "Jessieac", "Jesseica", "Jessieca", "Jssica", "eJessica",
    "eJssica", "Jsesica"),
  
  c("eJennifer", "eJnnifer", "Jeennifer", "Jenifer", "Jeninfer", "Jenneifer", 
    "Jennfier", "Jenniefer", "Jnenifer", "Jennifre", "ennifer", "Jennifeer",
    "Jennifr", "rennifeJ", "Jnnifer", "Jennier"),
  
  c("Jhn", "eJohn", "Jhn", "Joen", "Joh", "Johen", "Jhon", 
    "Jonh", "nohJ", "ohn", "oJhn", "John"),
  
  c("Jon", "on", "noJ", "Jo", "Jn", "Jeon"),
  
  c("eJoseph", "Joeseph", "Joesph", "Joseeph", "Joseh", "Josehp", "Josep", 
    "Jospeh", "Josepeh", "Josph", "Jseph", "Jsoeph", "Jeoseph", "oJseph", 
    "oseph"),
  
  c("Leinda", "iLnda", "aindL", "Lida", "Lidna", "Lina", "Linad", "Lind", 
    "Lindea", "Lineda", "Lnda", "Lnida", "eLinda"),
  
  c("Maerie", "Maire", "Maerie", "Marei", "Mar", "Mareie", "Mari", "Mariee", 
    "aMrie", "aMrie"), 
    
  c("Maery", "Marey", "May", "Mayr", "aMry", "ary", "Mray", 
    "Meary", "yarM"),
  
  c("eMichael", "ichael", "iMchael", "Mchael", "Mcihael", "Meichael", "Micael", 
    "Micehael", "Michae", "Michaeel", "Micheal", "Michel", "Miechael", "Mihael", 
    "Mihcael", "Michal"),
  
  c("atricia", "Paetricia", "Paricia", "Particia", "Patericia", "Patrciia", 
    "Paticia", "Patricai", "Patriceia", "ePatricia", "Patrici", "Patriecia",
    "Peatricia", "Ptaricia", "Ptricia"),
  
  c("iRchard", "eRichard", "Rchard", "Rcihard", "Ricard", "Ricehard", "Richad",
    "Richadr", "Richaerd", "Ricahrd", "Richar", "Richared", "Richeard", 
    "Richrad", "Rihcard", "Rihard", "Reichard"),
  
  c("obert", "oRbert", "Rbert", "Rboert", "Reobert", "Robeert", "Rober", 
    "Roberet", "Robet", "Robetr", "Robetr", "Robret", "Robrt", "Roebrt", 
    "Roert", "obert", "oRbert"),
  
  c("eSusan", "nusaS", "Seusan", "Ssan", "Ssuan", "Suasn", "Suesan", "Susaen", 
    "Susean", "Susn", "Susna", "usan", "uSsan", "nusaS", "eSusan", "Susa"),
  
  c("eWilliam", "illiam", "Weilliam", "Wileliam", "Wiliam", "Willeiam", 
    "Willia", "Williaem", "Willieam", "Willima", "Wliliam", "Wlliam", "iWlliam")
)

humans_mutated <- humans %>%
  mutate(
    Name = case_when(
      Name %in% names_to_replace[[1]] ~ "James",
      Name %in% names_to_replace[[2]] ~ "Barbara",
      Name %in% names_to_replace[[3]] ~ "David",
      Name %in% names_to_replace[[4]] ~ "Elizabeth",
      Name %in% names_to_replace[[5]] ~ "Jessica",
      Name %in% names_to_replace[[6]] ~ "Jennifer",
      Name %in% names_to_replace[[7]] ~ "John",
      Name %in% names_to_replace[[8]] ~ "Jon",
      Name %in% names_to_replace[[9]] ~ "Joseph",
      Name %in% names_to_replace[[10]] ~ "Linda",
      Name %in% names_to_replace[[11]] ~ "Marie",
      Name %in% names_to_replace[[12]] ~ "Mary",
      Name %in% names_to_replace[[13]] ~ "Michael",
      Name %in% names_to_replace[[14]] ~ "Patricia",
      Name %in% names_to_replace[[15]] ~ "Richard",
      Name %in% names_to_replace[[16]] ~ "Robert",
      Name %in% names_to_replace[[17]] ~ "Susan",
      Name %in% names_to_replace[[18]] ~ "William",
      TRUE ~ Name
    )
  )


num_names_mut <- humans_mutated$Name %>% table(.)
num_names_mut
```

2)  **For each of the genuine names identified in (1), produce a histogram showing the distribution of Damerau--Levenshtein distances from the genuine name to the miscassified data. Make sure distances from genuine names to other genuine names are not included in these distributions.\
    Arrange all of the histograms into one figure write a short interpretation of it intended for a non-statistician client.**

3)  **Write code that reclassifies names similar to problem (1), but fully automated. You should end up with a function that takes the original data set and returns a cleaned version. Compare this cleaned data frame to the one from problem (1) and quantify the accuracy (i.e. what proportion of rows match?). Make sure your automated process achieves 90%, but shoot for higher if possible!**
